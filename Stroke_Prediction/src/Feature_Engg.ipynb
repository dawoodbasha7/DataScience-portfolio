{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe49484d-b81b-44e2-9458-5c399b1f64e3",
   "metadata": {},
   "source": [
    "### Feture Engineering: Steps followed\n",
    "<pre>\n",
    "0. Data Splitting\n",
    "    * Since the dataset has an imbalanced target (stroke), use stratify=y in train_test_split.\n",
    "    * Perform all preprocessing steps only on the training set to avoid data leakage.\n",
    "    * The test set must remain unseen during transformation and oversampling.\n",
    "\n",
    "1. Data Imputation\n",
    "    * Check if the data is Missing Completely at Random (MCAR) or not.\n",
    "    * Use: Chi-square test for categorical predictors\n",
    "              Logistic regression (Missing Indicator ~ Predictors) for numerical ones\n",
    "    * Based on expert-backed approaches, apply Iterative Imputer (with median) on numerical missing values (e.g., bmi).\n",
    "\n",
    "2. Handle Categorical Columns\n",
    "    * Apply One-Hot Encoding to convert categorical variables into numerical format.\n",
    "    * This ensures compatibility with models and SMOTE later.\n",
    "\n",
    "3. Transform Numerical Columns\n",
    "    * If numerical features are skewed, apply transformations like:\n",
    "            PowerTransformer, \n",
    "            log, or \n",
    "            Box-Cox depending on distribution.\n",
    "    * This improves scaling and model performance.\n",
    "\n",
    "4. Normalization/Scaling\n",
    "    * Use StandardScaler or MinMaxScaler on numerical columns.\n",
    "    * Scaling is essential before SMOTE, as it relies on distance metrics.\n",
    "\n",
    "5. SMOTE (Over-sampling Technique for Imbalanced Data)\n",
    "    * Apply SMOTE only on the training set.\n",
    "    * Perform after all preprocessing steps (imputation, encoding, transformation, scaling).\n",
    "    * SMOTE should never touch the test data to avoid information leakage.\n",
    "\n",
    "6. Modeling\n",
    "    * Train the model using the balanced and preprocessed training data.\n",
    "    * Evaluate it using the preprocessed (but not oversampled) test set.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c732344f-9710-4851-8d43-b810fe755318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ad4cca-00da-48ff-ab77-50f9ad9fb573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1  Female  61.0             0              0          Yes  Self-employed   \n",
       "2    Male  80.0             0              1          Yes        Private   \n",
       "3  Female  49.0             0              0          Yes        Private   \n",
       "4  Female  79.0             1              0          Yes  Self-employed   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban             228.69  36.6  formerly smoked       1  \n",
       "1          Rural             202.21   NaN     never smoked       1  \n",
       "2          Rural             105.92  32.5     never smoked       1  \n",
       "3          Urban             171.23  34.4           smokes       1  \n",
       "4          Rural             174.12  24.0     never smoked       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48b1939-f751-4a32-8c1a-2b6a903d81a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.226614</td>\n",
       "      <td>106.147677</td>\n",
       "      <td>28.893237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.612647</td>\n",
       "      <td>45.283560</td>\n",
       "      <td>7.854067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>10.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>77.245000</td>\n",
       "      <td>23.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>28.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>114.090000</td>\n",
       "      <td>33.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  avg_glucose_level          bmi\n",
       "count  5110.000000        5110.000000  4909.000000\n",
       "mean     43.226614         106.147677    28.893237\n",
       "std      22.612647          45.283560     7.854067\n",
       "min       0.080000          55.120000    10.300000\n",
       "25%      25.000000          77.245000    23.500000\n",
       "50%      45.000000          91.885000    28.100000\n",
       "75%      61.000000         114.090000    33.100000\n",
       "max      82.000000         271.740000    97.600000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521c56ff-40ef-4aea-a212-372828f0372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['age', 'avg_glucose_level', 'bmi']\n",
      "Categorical columns: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'hypertension', 'heart_disease', 'stroke']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Automatically select columns\n",
    "numerical_selector = selector(dtype_include=['int64', 'float64'])\n",
    "categorical_selector = selector(dtype_include=['object', 'category', 'bool'])\n",
    "\n",
    "# Get initial lists\n",
    "numerical_cols = numerical_selector(df)\n",
    "categorical_cols = categorical_selector(df)\n",
    "\n",
    "# Identify binary numeric columns (with only two unique values)\n",
    "binary_numerical_cols = [col for col in numerical_cols \n",
    "                         if df[col].nunique(dropna=False) == 2]\n",
    "\n",
    "# Move them from numerical to categorical\n",
    "numerical_cols = [col for col in numerical_cols if col not in binary_numerical_cols]\n",
    "categorical_cols = categorical_cols + binary_numerical_cols\n",
    "\n",
    "# Results\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884f826-ed4f-4e4d-87d8-429fddfce5d3",
   "metadata": {},
   "source": [
    "### 0. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84606d02-efc7-4696-9b5d-417bfa8a9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "target_col = 'stroke'\n",
    "\n",
    "numerical_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "categorical_cols = ['gender', 'hypertension', 'heart_disease', 'ever_married',\n",
    "                    'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "# Step 1: Split data\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af662d10-7151-4573-9873-faab1fd71c03",
   "metadata": {},
   "source": [
    "### 1. Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c7c26-2d16-4e36-80c6-75a11c6e062b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Is the missing data random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c277afdd-e748-491c-9a05-5f303dc33029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m X = sm.add_constant(df_enc.drop(\u001b[33m'\u001b[39m\u001b[33mmissing_bmi\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m))\n\u001b[32m      9\u001b[39m y = df_enc[\u001b[33m'\u001b[39m\u001b[33mmissing_bmi\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model = \u001b[43msm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(model.summary())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2601\u001b[39m, in \u001b[36mLogit.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[39m\n\u001b[32m   2598\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel.fit.\u001b[34m__doc__\u001b[39m)\n\u001b[32m   2599\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params=\u001b[38;5;28;01mNone\u001b[39;00m, method=\u001b[33m'\u001b[39m\u001b[33mnewton\u001b[39m\u001b[33m'\u001b[39m, maxiter=\u001b[32m35\u001b[39m,\n\u001b[32m   2600\u001b[39m         full_output=\u001b[32m1\u001b[39m, disp=\u001b[32m1\u001b[39m, callback=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m2601\u001b[39m     bnryfit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m                          \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2609\u001b[39m     discretefit = LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[32m   2610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:243\u001b[39m, in \u001b[36mDiscreteModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m mlefit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m                     \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\statsmodels\\base\\model.py:582\u001b[39m, in \u001b[36mLikelihoodModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[39m\n\u001b[32m    580\u001b[39m     Hinv = cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mnewton\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     Hinv = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHessian\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m / nobs\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[32m    584\u001b[39m     H = -\u001b[32m1\u001b[39m * \u001b[38;5;28mself\u001b[39m.hessian(xopt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:669\u001b[39m, in \u001b[36minv\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    666\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    668\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     ainv = \u001b[43m_umath_linalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:163\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "\n",
    "df['missing_bmi'] = df['bmi'].isna().astype(int)\n",
    "cat_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'hypertension', 'heart_disease', 'stroke']\n",
    "num_cols = ['age', 'avg_glucose_level']\n",
    "\n",
    "df_enc = pd.get_dummies(df[categorical_cols + numerical_cols + ['missing_bmi']], drop_first=True).astype(float)\n",
    "df_enc = df_enc.dropna()\n",
    "\n",
    "X = sm.add_constant(df_enc.drop('missing_bmi', axis=1))\n",
    "y = df_enc['missing_bmi']\n",
    "\n",
    "model = sm.Logit(y, X).fit(disp=0)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892fce9-f406-47e4-9511-f08e0c0114dc",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The missingness in the bmi column was analyzed using logistic regression and found to be significantly related to features like hypertension and stroke. This indicates that the missing data is Missing At Random (MAR), not completely random. Therefore, a model-based imputation method was chosen to leverage these relationships for accurate imputation.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947d763-8935-4b00-9128-0dff7c8b6a2e",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ba6c09-dc4f-4b68-a7af-7160ae353369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bmi_imputer = IterativeImputer(random_state=0, initial_strategy='median')\n",
    "X_train_bmi = X_train[['bmi']]\n",
    "X_test_bmi = X_test[['bmi']]\n",
    "\n",
    "X_train['bmi'] = bmi_imputer.fit_transform(X_train_bmi)\n",
    "X_test['bmi'] = bmi_imputer.transform(X_test_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc9ed9-d7ea-4bb7-b981-5fe05fa9e43b",
   "metadata": {},
   "source": [
    "### Handling categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f0d02b-f997-4d4f-bf13-d98dd3a1e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>formerly smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>smokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male             0              1          Yes        Private   \n",
       "1  Female             0              0          Yes  Self-employed   \n",
       "2    Male             0              1          Yes        Private   \n",
       "3  Female             0              0          Yes        Private   \n",
       "4  Female             1              0          Yes  Self-employed   \n",
       "\n",
       "  Residence_type   smoking_status  \n",
       "0          Urban  formerly smoked  \n",
       "1          Rural     never smoked  \n",
       "2          Rural     never smoked  \n",
       "3          Urban           smokes  \n",
       "4          Rural     never smoked  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b77f837-9444-4e7d-86f7-97ec590b27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ohe_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "\n",
    "# Fit encoder\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "X_train_ohe = pd.DataFrame(ohe.fit_transform(X_train[cat_ohe_cols]), \n",
    "                           columns=ohe.get_feature_names_out(cat_ohe_cols),\n",
    "                           index=X_train.index)\n",
    "X_test_ohe = pd.DataFrame(ohe.transform(X_test[cat_ohe_cols]), \n",
    "                          columns=ohe.get_feature_names_out(cat_ohe_cols),\n",
    "                          index=X_test.index)\n",
    "\n",
    "# Drop original and concatenate\n",
    "X_train = pd.concat([X_train.drop(columns=cat_ohe_cols), X_train_ohe], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns=cat_ohe_cols), X_test_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be3bddb-dee7-4700-9765-1323d4321069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107.84</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.32</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.49</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.57</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103.66</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hypertension  heart_disease  avg_glucose_level   bmi  gender_Male  \\\n",
       "2226  52.0             0              0             107.84  22.0          0.0   \n",
       "3927  62.0             0              0              88.32  36.3          0.0   \n",
       "3358  81.0             0              1              95.49  29.4          1.0   \n",
       "4152  55.0             0              0              73.57  28.0          1.0   \n",
       "4866  37.0             0              0             103.66  36.1          0.0   \n",
       "\n",
       "      gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
       "2226           0.0               1.0                     0.0   \n",
       "3927           0.0               1.0                     0.0   \n",
       "3358           0.0               0.0                     0.0   \n",
       "4152           0.0               1.0                     0.0   \n",
       "4866           0.0               1.0                     0.0   \n",
       "\n",
       "      work_type_Private  work_type_Self-employed  work_type_children  \\\n",
       "2226                0.0                      0.0                 0.0   \n",
       "3927                1.0                      0.0                 0.0   \n",
       "3358                0.0                      1.0                 0.0   \n",
       "4152                0.0                      1.0                 0.0   \n",
       "4866                1.0                      0.0                 0.0   \n",
       "\n",
       "      Residence_type_Urban  smoking_status_formerly smoked  \\\n",
       "2226                   0.0                             1.0   \n",
       "3927                   1.0                             0.0   \n",
       "3358                   0.0                             0.0   \n",
       "4152                   0.0                             0.0   \n",
       "4866                   1.0                             0.0   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes  \n",
       "2226                          0.0                    0.0  \n",
       "3927                          0.0                    0.0  \n",
       "3358                          0.0                    0.0  \n",
       "4152                          0.0                    1.0  \n",
       "4866                          0.0                    1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43db01-cfd0-42a3-a0ce-863babaf04d8",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6e4cd54-cc52-4719-b4d7-4883294e3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='box-cox')\n",
    "\n",
    "# Fit on train and transform both train and test\n",
    "X_train[['bmi', 'avg_glucose_level']] = pt.fit_transform(X_train[['bmi', 'avg_glucose_level']])\n",
    "X_test[['bmi', 'avg_glucose_level']] = pt.transform(X_test[['bmi', 'avg_glucose_level']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0595118-4d1d-4f9f-b0ab-a7eb336106bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>-0.904104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.163428</td>\n",
       "      <td>1.013194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091233</td>\n",
       "      <td>0.208501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.849117</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337227</td>\n",
       "      <td>0.992152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hypertension  heart_disease  avg_glucose_level       bmi  \\\n",
       "2226  52.0             0              0           0.448242 -0.904104   \n",
       "3927  62.0             0              0          -0.163428  1.013194   \n",
       "3358  81.0             0              1           0.091233  0.208501   \n",
       "4152  55.0             0              0          -0.849117  0.021761   \n",
       "4866  37.0             0              0           0.337227  0.992152   \n",
       "\n",
       "      gender_Male  gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
       "2226          0.0           0.0               1.0                     0.0   \n",
       "3927          0.0           0.0               1.0                     0.0   \n",
       "3358          1.0           0.0               0.0                     0.0   \n",
       "4152          1.0           0.0               1.0                     0.0   \n",
       "4866          0.0           0.0               1.0                     0.0   \n",
       "\n",
       "      work_type_Private  work_type_Self-employed  work_type_children  \\\n",
       "2226                0.0                      0.0                 0.0   \n",
       "3927                1.0                      0.0                 0.0   \n",
       "3358                0.0                      1.0                 0.0   \n",
       "4152                0.0                      1.0                 0.0   \n",
       "4866                1.0                      0.0                 0.0   \n",
       "\n",
       "      Residence_type_Urban  smoking_status_formerly smoked  \\\n",
       "2226                   0.0                             1.0   \n",
       "3927                   1.0                             0.0   \n",
       "3358                   0.0                             0.0   \n",
       "4152                   0.0                             0.0   \n",
       "4866                   1.0                             0.0   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes  \n",
       "2226                          0.0                    0.0  \n",
       "3927                          0.0                    0.0  \n",
       "3358                          0.0                    0.0  \n",
       "4152                          0.0                    1.0  \n",
       "4866                          0.0                    1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da63234-625d-494c-89bd-184da4b696f0",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b8c2a6d-ae0b-44c7-8bf3-c8e8bc0c32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on train, transform train and test\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f798f52-156f-455c-834f-5e654a5f4ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>0.389044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>-0.904104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>0.833687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.163428</td>\n",
       "      <td>1.013194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>1.678510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091233</td>\n",
       "      <td>0.208501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0.522437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.849117</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>-0.277921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337227</td>\n",
       "      <td>0.992152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  hypertension  heart_disease  avg_glucose_level       bmi  \\\n",
       "2226  0.389044             0              0           0.448242 -0.904104   \n",
       "3927  0.833687             0              0          -0.163428  1.013194   \n",
       "3358  1.678510             0              1           0.091233  0.208501   \n",
       "4152  0.522437             0              0          -0.849117  0.021761   \n",
       "4866 -0.277921             0              0           0.337227  0.992152   \n",
       "\n",
       "      gender_Male  gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
       "2226          0.0           0.0               1.0                     0.0   \n",
       "3927          0.0           0.0               1.0                     0.0   \n",
       "3358          1.0           0.0               0.0                     0.0   \n",
       "4152          1.0           0.0               1.0                     0.0   \n",
       "4866          0.0           0.0               1.0                     0.0   \n",
       "\n",
       "      work_type_Private  work_type_Self-employed  work_type_children  \\\n",
       "2226                0.0                      0.0                 0.0   \n",
       "3927                1.0                      0.0                 0.0   \n",
       "3358                0.0                      1.0                 0.0   \n",
       "4152                0.0                      1.0                 0.0   \n",
       "4866                1.0                      0.0                 0.0   \n",
       "\n",
       "      Residence_type_Urban  smoking_status_formerly smoked  \\\n",
       "2226                   0.0                             1.0   \n",
       "3927                   1.0                             0.0   \n",
       "3358                   0.0                             0.0   \n",
       "4152                   0.0                             0.0   \n",
       "4866                   1.0                             0.0   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes  \n",
       "2226                          0.0                    0.0  \n",
       "3927                          0.0                    0.0  \n",
       "3358                          0.0                    0.0  \n",
       "4152                          0.0                    1.0  \n",
       "4866                          0.0                    1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11b505fc-c6d7-4055-b171-5febb23efed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226    0\n",
       "3927    0\n",
       "3358    0\n",
       "4152    0\n",
       "4866    0\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c2650-af3e-4497-bf04-8993a86343e2",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6adfade8-28cd-46b4-8611-404955deee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "                            Feature  MI Score\n",
      "0                              age  0.034544\n",
      "4                              bmi  0.012080\n",
      "7                 ever_married_Yes  0.009049\n",
      "3                avg_glucose_level  0.005901\n",
      "11              work_type_children  0.004515\n",
      "8           work_type_Never_worked  0.001774\n",
      "9                work_type_Private  0.001752\n",
      "15           smoking_status_smokes  0.001686\n",
      "1                     hypertension  0.001492\n",
      "2                    heart_disease  0.000832\n",
      "14     smoking_status_never smoked  0.000647\n",
      "5                      gender_Male  0.000000\n",
      "6                     gender_Other  0.000000\n",
      "10         work_type_Self-employed  0.000000\n",
      "13  smoking_status_formerly smoked  0.000000\n",
      "12            Residence_type_Urban  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Compute Mutual Information\n",
    "mi_scores = mutual_info_classif(X_train, y_train, discrete_features='auto', random_state=42)\n",
    "mi_df = pd.DataFrame({'Feature': X_train.columns, 'MI Score': mi_scores}).sort_values(by='MI Score', ascending=False)\n",
    "\n",
    "print(\"Mutual Information Scores:\\n\", mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6df68979-68b7-42c7-823c-2cc952200c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Female', 'Male', 'Other'], dtype=object), array(['No', 'Yes'], dtype=object), array(['Govt_job', 'Never_worked', 'Private', 'Self-employed', 'children'],\n",
      "      dtype=object), array(['Rural', 'Urban'], dtype=object), array(['Unknown', 'formerly smoked', 'never smoked', 'smokes'],\n",
      "      dtype=object)]\n",
      "Index(['gender_Male', 'gender_Other', 'ever_married_Yes',\n",
      "       'work_type_Never_worked', 'work_type_Private',\n",
      "       'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban',\n",
      "       'smoking_status_formerly smoked', 'smoking_status_never smoked',\n",
      "       'smoking_status_smokes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ohe.categories_)\n",
    "print(X_train_ohe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2370af18-afb4-41f7-8373-13d4ccb41be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sekect the columns using ---methods\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15b5cbb2-77e2-48e4-9591-0b36b5e0046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'ever_married_Yes', 'work_type_children', 'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked']\n"
     ]
    }
   ],
   "source": [
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"Selected Features:\", list(selected_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4bd7c7-175b-4e5e-adcf-1571de9ec4e9",
   "metadata": {},
   "source": [
    "## APply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f4317d9-8c9e-4e0a-9ed9-2d486500bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply SMOTE only on training data\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0440ba-d4e0-443f-b96f-dae90863c60b",
   "metadata": {},
   "source": [
    "## BAse line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be3336d4-7e06-4e14-9831-31438ab9b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.49970609845701686\n",
      "CV F1 Score: 0.2665360117589417\n",
      "CV Precision: 0.19985304922850844\n",
      "CV Recall: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "# Initialize dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "# Cross-validation on balanced training set\n",
    "cv_results = cross_validate(dummy_clf, X_train_bal, y_train_bal, cv=5, scoring=scoring)\n",
    "\n",
    "# Print average scores\n",
    "print(\"CV Accuracy:\", cv_results['test_accuracy'].mean())\n",
    "print(\"CV F1 Score:\", cv_results['test_f1'].mean())\n",
    "print(\"CV Precision:\", cv_results['test_precision'].mean())\n",
    "print(\"CV Recall:\", cv_results['test_recall'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad5a0ea9-2f5f-4f40-a968-1c34a61147c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ola\\datascience\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-08-20 21:12:31,507] A new study created in memory with name: no-name-69e74ac4-97ae-40bc-a9df-975b13d73db2\n",
      "C:\\Users\\Ola\\AppData\\Local\\Temp\\ipykernel_10060\\1573868448.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 100)\n",
      "[W 2025-08-20 21:12:31,556] Trial 0 failed with parameters: {'penalty': 'none', 'C': 73.47132786929942, 'max_iter': 2904} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n5 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\Ola\\\\datascience\\\\Lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 859, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"C:\\\\Users\\\\Ola\\\\datascience\\\\Lib\\\\site-packages\\\\sklearn\\\\base.py\", line 1358, in wrapper\\n    estimator._validate_params()\\n  File \"C:\\\\Users\\\\Ola\\\\datascience\\\\Lib\\\\site-packages\\\\sklearn\\\\base.py\", line 471, in _validate_params\\n    validate_parameter_constraints(\\n  File \"C:\\\\Users\\\\Ola\\\\datascience\\\\Lib\\\\site-packages\\\\sklearn\\\\utils\\\\_param_validation.py\", line 98, in validate_parameter_constraints\\n    raise InvalidParameterError(\\nsklearn.utils._param_validation.InvalidParameterError: The \\'penalty\\' parameter of LogisticRegression must be a str among {\\'elasticnet\\', \\'l1\\', \\'l2\\'} or None. Got \\'none\\' instead.\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\AppData\\Local\\Temp\\ipykernel_10060\\1573868448.py\", line 76, in <lambda>\n",
      "    study_lr.optimize(lambda trial: objective(trial, 'logistic'), n_trials=50)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\AppData\\Local\\Temp\\ipykernel_10060\\1573868448.py\", line 71, in objective\n",
      "    scores = cross_val_score(clf, X_train_bal, y_train_bal, cv=cv, scoring=scorer)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "[W 2025-08-20 21:12:31,562] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Example: create study for Logistic Regression\u001b[39;00m\n\u001b[32m     75\u001b[39m study_lr = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mstudy_lr\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogistic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Example: create study for Decision Tree\u001b[39;00m\n\u001b[32m     79\u001b[39m study_dt = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Example: create study for Logistic Regression\u001b[39;00m\n\u001b[32m     75\u001b[39m study_lr = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m study_lr.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogistic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, n_trials=\u001b[32m50\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Example: create study for Decision Tree\u001b[39;00m\n\u001b[32m     79\u001b[39m study_dt = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, model_type)\u001b[39m\n\u001b[32m     56\u001b[39m     clf = XGBClassifier(n_estimators=n_estimators,\n\u001b[32m     57\u001b[39m                         max_depth=max_depth,\n\u001b[32m     58\u001b[39m                         learning_rate=learning_rate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m                         eval_metric=\u001b[33m'\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     68\u001b[39m                         random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Cross-validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\Ola\\datascience\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Use F1 or recall as scoring\n",
    "scorer = make_scorer(f1_score)  # you can also switch to recall_score\n",
    "\n",
    "# Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial, model_type='logistic'):\n",
    "    if model_type == 'logistic':\n",
    "        # Hyperparameters\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', 'none'])\n",
    "        solver_options = {'l1': 'liblinear', 'l2': 'lbfgs', 'elasticnet': 'saga', 'none': 'lbfgs'}\n",
    "        solver = solver_options[penalty]\n",
    "        \n",
    "        l1_ratio = None\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "        \n",
    "        C = trial.suggest_loguniform('C', 0.01, 100)\n",
    "        max_iter = trial.suggest_int('max_iter', 100, 5000)\n",
    "        \n",
    "        clf = LogisticRegression(penalty=penalty, solver=solver, C=C, l1_ratio=l1_ratio,\n",
    "                                 max_iter=max_iter, class_weight='balanced', random_state=42)\n",
    "    \n",
    "    elif model_type == 'decision_tree':\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 50)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "        criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        clf = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                     min_samples_split=min_samples_split,\n",
    "                                     min_samples_leaf=min_samples_leaf,\n",
    "                                     criterion=criterion,\n",
    "                                     class_weight='balanced',\n",
    "                                     random_state=42)\n",
    "    \n",
    "    elif model_type == 'xgboost':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "        subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "        gamma = trial.suggest_float('gamma', 0, 5)\n",
    "        reg_alpha = trial.suggest_float('reg_alpha', 0, 5)\n",
    "        reg_lambda = trial.suggest_float('reg_lambda', 0, 5)\n",
    "        min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "        \n",
    "        clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            learning_rate=learning_rate,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            gamma=gamma,\n",
    "                            reg_alpha=reg_alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            scale_pos_weight=1,  # adjust if your classes are imbalanced\n",
    "                            use_label_encoder=False,\n",
    "                            eval_metric='logloss',\n",
    "                            random_state=42)\n",
    "    \n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(clf, X_train_bal, y_train_bal, cv=cv, scoring=scorer)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Example: create study for Logistic Regression\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_lr.optimize(lambda trial: objective(trial, 'logistic'), n_trials=50)\n",
    "\n",
    "# Example: create study for Decision Tree\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(lambda trial: objective(trial, 'decision_tree'), n_trials=50)\n",
    "\n",
    "# Example: create study for XGBoost\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(lambda trial: objective(trial, 'xgboost'), n_trials=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee8973-b8fb-4976-aab6-62e12a8a0a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
